{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd047cd",
   "metadata": {},
   "source": [
    "\n",
    "# Multilayer Perceptron for MNIST Classification\n",
    "\n",
    "In this notebook, we will explore the use of a Multilayer Perceptron (MLP) to classify handwritten digits from the MNIST dataset. The MNIST dataset is a classic dataset in the machine learning community, consisting of 70,000 images of handwritten digits (0-9) with corresponding labels.\n",
    "\n",
    "## Introduction to MLP\n",
    "\n",
    "A Multilayer Perceptron (MLP) is a type of artificial neural network that consists of at least three layers of nodes: an input layer, one or more hidden layers, and an output layer. Each node (neuron) in one layer connects with a certain weight to every node in the next layer. MLPs are capable of modeling complex relationships in data.\n",
    "\n",
    "## Important Hyperparameters\n",
    "\n",
    "When working with MLPs, several hyperparameters are crucial to understand and experiment with:\n",
    "\n",
    "- **Number of Hidden Layers**: The number of hidden layers can affect the model's ability to learn complex patterns. More layers can capture more complexity but also increase the risk of overfitting.\n",
    "- **Number of Neurons per Layer**: The number of neurons in each hidden layer determines the model's capacity. More neurons can learn more features but also increase computation time.\n",
    "- **Activation Function**: The activation function introduces non-linearity into the model, allowing it to learn more complex patterns. Common activation functions include ReLU, Sigmoid, and Tanh.\n",
    "- **Use of Bias**: Bias terms can help the model learn patterns that do not pass through the origin.\n",
    "\n",
    "We will also explore how to build a graphical user interface (GUI) to draw and classify digits using the trained MLP model.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "At the end of the notebook, you will be given a challenge to further solidify your understanding of MLPs and their hyperparameters.\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from ipywidgets import interact, widgets, VBox, HBox\n",
    "from IPython.display import display\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Define a function to create the MLP model\n",
    "def create_model(input_size, hidden_sizes, output_size, activation_fn, use_bias):\n",
    "    layers = []\n",
    "    previous_size = input_size\n",
    "    for size in hidden_sizes:\n",
    "        layers.append(nn.Linear(previous_size, size, bias=use_bias))\n",
    "        if activation_fn == 'ReLU':\n",
    "            layers.append(nn.ReLU())\n",
    "        elif activation_fn == 'Sigmoid':\n",
    "            layers.append(nn.Sigmoid())\n",
    "        elif activation_fn == 'Tanh':\n",
    "            layers.append(nn.Tanh())\n",
    "        previous_size = size\n",
    "    layers.append(nn.Linear(previous_size, output_size, bias=use_bias))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images.view(images.shape[0], -1))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
    "\n",
    "# Testing function\n",
    "def test_model(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            outputs = model(images.view(images.shape[0], -1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Accuracy: {100 * correct / total} %\")\n",
    "\n",
    "# Function to handle training when the button is clicked\n",
    "def on_button_click(b):\n",
    "    input_size = 784\n",
    "    output_size = 10\n",
    "    hidden_sizes = [sizes_widget.value for _ in range(layers_widget.value)]\n",
    "    activation_fn = activation_fn_widget.value\n",
    "    use_bias = use_bias_widget.value\n",
    "    save_model = save_model_widget.value\n",
    "    \n",
    "    print(f'Creating model with parameters:\\nNumber of hidden layers: {layers_widget}\\nLayers size: {hidden_sizes}\\nActivation function: {activation_fn}\\nBias: {use_bias}')\n",
    "    model = create_model(input_size, hidden_sizes, output_size, activation_fn, use_bias)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    train_model(model, trainloader, criterion, optimizer, epochs=5)\n",
    "    test_model(model, testloader)\n",
    "    \n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), 'saved_mlp.pth')\n",
    "        print(\"Model saved to 'saved_mlp.pth'\")\n",
    "        config = {\n",
    "            'input_size': input_size,\n",
    "            'hidden_sizes': hidden_sizes,\n",
    "            'output_size': output_size,\n",
    "            'activation_fn': activation_fn,\n",
    "            'use_bias': use_bias\n",
    "        }\n",
    "        with open('saved_mlp_config.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "    \n",
    "\n",
    "# Interactive widget setup\n",
    "activation_fn_widget = widgets.Dropdown(options=['ReLU', 'Sigmoid', 'Tanh'], description='Activation:')\n",
    "use_bias_widget = widgets.Checkbox(value=True, description='Use Bias')\n",
    "layers_widget = widgets.IntSlider(min=1, max=5, step=1, value=2, description='Layers')\n",
    "sizes_widget = widgets.IntSlider(min=10, max=200, step=10, value=50, description='Layer Size')\n",
    "save_model_widget = widgets.Checkbox(value=False, description='Save Model')\n",
    "run_button = widgets.Button(description=\"Run\")\n",
    "\n",
    "# Set up the event handler for the button\n",
    "run_button.on_click(on_button_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(VBox([activation_fn_widget, use_bias_widget, layers_widget, sizes_widget, save_model_widget, run_button]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a simple model for the GUI if the file does not exist\n",
    "model_path = 'saved_mlp.pth'\n",
    "config_path = 'saved_mlp_config.json'\n",
    "\n",
    "try:\n",
    "    # Load the model configuration\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    print(f'Loading {model_path} state')\n",
    "    simple_model = create_model(\n",
    "        config['input_size'], \n",
    "        config['hidden_sizes'], \n",
    "        config['output_size'], \n",
    "        config['activation_fn'], \n",
    "        config['use_bias']\n",
    "    )\n",
    "    simple_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Alternatively, manually create a new model here with new hyperparameters\n",
    "    simple_model = create_model(784, [128, 64], 10, 'ReLU', True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(simple_model.parameters(), lr=0.01, momentum=0.9)\n",
    "    train_model(simple_model, trainloader, criterion, optimizer, epochs=5)\n",
    "    torch.save(simple_model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8346f",
   "metadata": {},
   "source": [
    "\n",
    "## Drawing and Classifying Digits\n",
    "\n",
    "Next, we will create a graphical user interface (GUI) to draw and classify digits using the trained MLP model. The GUI will allow you to draw a digit, reset the canvas, and classify the drawn digit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# GUI for inputting numbers\n",
    "class DigitClassifierGUI:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Digit Classifier\")\n",
    "        \n",
    "        self.canvas = tk.Canvas(self.root, width=280, height=280, bg=\"white\")\n",
    "        self.canvas.grid(row=0, column=0, columnspan=2)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.paint)\n",
    "        \n",
    "        self.reset_button = tk.Button(self.root, text=\"Reset\", command=self.reset)\n",
    "        self.reset_button.grid(row=1, column=0)\n",
    "        \n",
    "        self.classify_button = tk.Button(self.root, text=\"Classify\", command=self.classify)\n",
    "        self.classify_button.grid(row=1, column=1)\n",
    "        \n",
    "        self.image = np.zeros((28, 28))\n",
    "        \n",
    "        self.root.mainloop()\n",
    "    \n",
    "    def paint(self, event):\n",
    "        x, y = event.x, event.y\n",
    "        self.canvas.create_rectangle((x, y) * 2, outline=\"black\", width=20)\n",
    "        self.image[y//10, x//10] = 1.0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.image = np.zeros((28, 28))\n",
    "        \n",
    "    def classify(self):\n",
    "        input_tensor = torch.tensor(self.image, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        input_tensor = input_tensor.view(1, -1)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            messagebox.showinfo(\"Prediction\", f'Predicted Number: {predicted.item()}')\n",
    "            print(f'Predicted Number: {predicted.item()}')\n",
    "\n",
    "# Initialize the GUI\n",
    "DigitClassifierGUI(simple_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06597eeb",
   "metadata": {},
   "source": [
    "\n",
    "## Challenge\n",
    "\n",
    "Now that you have learned how to create and train a Multilayer Perceptron, and how to use it to classify handwritten digits, it's time for a challenge!\n",
    "\n",
    "### Challenge\n",
    "\n",
    "1. **Experiment with Hyperparameters**: Modify the number of hidden layers, the number of neurons per layer, the activation function, and the use of bias in the MLP model. Train the model with these different configurations and observe how the performance changes. Try to find the best configuration that gives you the highest accuracy on the MNIST test set.\n",
    "\n",
    "2. **Implement a Different Activation Function**: Research and implement a different activation function (e.g., Leaky ReLU, ELU). Integrate this activation function into the `create_model` function and observe how it affects the model's performance.\n",
    "\n",
    "3. **Data Augmentation**: Implement data augmentation techniques (e.g., rotation, scaling, translation) to artificially increase the size of the training dataset. Train the MLP model with the augmented dataset and observe if there is any improvement in the accuracy.\n",
    "\n",
    "### Tips\n",
    "\n",
    "- Use the `torchvision.transforms` module to implement data augmentation.\n",
    "- Keep track of the hyperparameters and their corresponding performance to identify the best configuration.\n",
    "\n",
    "Good luck and have fun experimenting!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
